version: "3.9"
services:
  postgres:
    container_name: "postgres"
    image: "postgres:16.3"
    environment:
      - "POSTGRES_USER=postgres"
      - "POSTGRES_PASSWORD=postgres"
      - "PGDATA=/data/postgres"
    volumes:
      - "${HOME}/data/postgres:/data/postgres"
      - "./data/postgres/my_data.sql:/docker-entrypoint-initdb.d/my_data.sql"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"

  mysql:
    container_name: "mysql"
    image: "mysql:8.4.0"
    environment:
      - "MYSQL_ROOT_PASSWORD=root"
    command: "--default-authentication-plugin=mysql_native_password"
    volumes:
      - "${HOME}/data/mysql:/var/lib/mysql"
      - "./data/mysql/my_data.sql:/docker-entrypoint-initdb.d/my_data.sql"
    healthcheck:
      test: [ "CMD-SHELL", "mysqladmin" ,"ping", "-h", "localhost", "-u", "root", "-p$$MYSQL_ROOT_PASSWORD" ]
      timeout: 20s
      retries: 10
    ports:
      - "3306:3306"

  solace-server:
    container_name: "solace"
    image: "solace/solace-pubsub-standard:10.8"
    environment:
      - "username_admin_globalaccesslevel=admin"
      - "username_admin_password=admin"
      - "system_scaling_maxconnectioncount=100"
    volumes:
      - "${HOME}/data/solace:/var/lib/solace"
    healthcheck:
      test: [ "CMD-SHELL", "curl", "--output", "/dev/null", "--silent", "--head", "--fail", "http://localhost:8080" ]
      interval: "30s"
      timeout: "5s"
      retries: 3
    ports:
      - "8080:8080"
      - "55554:55555"
    shm_size: "1g"
    ulimits:
      core: -1
      nofile:
        soft: 2448
        hard: 6592
    deploy:
      restart_policy:
        condition: "on-failure"
        max_attempts: 1

  solace:
    container_name: "solace-data"
    image: "solace/solace-pubsub-standard:10.8"
    entrypoint: [ "/bin/sh", "-c", "/opt/app/my_data.sh" ]
    volumes:
      - "./data/solace:/opt/app"
    depends_on:
      solace-server:
        condition: "service_healthy"

  cassandra:
    container_name: "cassandra"
    image: "datastax/dse-server:6.8.48"
    environment:
      - "DS_LICENSE=accept"
    volumes:
      - "${HOME}/data/cassandra:/var/lib/cassandra"
      - "./data/cassandra/my_data.cql:/docker-entrypoint-initdb.d/my_data.cql"
    healthcheck:
      test: [ "CMD-SHELL", "[ $$(nodetool statusgossip) = running ]" ]
      interval: 30s
      timeout: 10s
      retries: 5
    ports:
      - "9042:9042"
    # Allow DSE to lock memory with mlock
    cap_add:
      - IPC_LOCK
    ulimits:
      memlock: -1

  httpbin:
    container_name: "http"
    image: "kennethreitz/httpbin:latest"
    environment:
      - "GUNICORN_CMD_ARGS=--capture-output --error-logfile - --access-logfile - --access-logformat '%(h)s %(t)s %(r)s %(s)s Host: %({Host}i)s}'"
    ports:
      - "80:80"

  kafka-server:
    container_name: "kafka"
    image: "confluentinc/confluent-local:7.6.1"
    environment:
      - "KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
      - "KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT"
      - "KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092"
      - "KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://localhost:29093,PLAINTEXT_HOST://0.0.0.0:9092"
    volumes:
      - "${HOME}/data/kafka:/var/lib/kafka/data"
    healthcheck:
      test: [ "CMD-SHELL", "/bin/sh", "-c", "kafka-topics", "--bootstrap-server", "kafka:29092", "--list" ]
      interval: "15s"
      timeout: "5s"
      retries: 3
    ports:
      - "9092:9092"
    expose:
      - "29092"

  kafka:
    container_name: "kafka-data"
    image: "confluentinc/confluent-local:7.6.1"
    entrypoint: [ "/bin/sh", "-c", "/opt/app/my_data.sh" ]
    volumes:
      - "./data/kafka:/opt/app"
    depends_on:
      kafka-server:
        condition: "service_healthy"

  elasticsearch:
    container_name: "elasticsearch"
    image: "docker.elastic.co/elasticsearch/elasticsearch:8.13.4"
    environment:
      - "node.name=elasticsearch"
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - "ELASTIC_PASSWORD=elasticsearch"
      - "discovery.type=single-node"
    volumes:
      - "./data/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z"
      - "${HOME}/data/elasticsearch:/usr/share/elasticsearch/data:Z"
    ports:
      - "9200:9200"
      - "9300:9300"
    restart: "unless-stopped"

  mongodb-server:
    container_name: "mongodb"
    image: "mongo:7.0.11"
    environment:
      - "MONGO_INITDB_ROOT_USERNAME=user"
      - "MONGO_INITDB_ROOT_PASSWORD=password"
    volumes:
      - "${HOME}/data/mongodb:/data/db"
    ports:
      - "27017:27017"

  mongodb:
    container_name: "mongodb-connect"
    image: "mongodb/mongodb-community-server:7.0.11-ubi8"
    environment:
      - "CONN_STR=mongodb://user:password@mongodb-server"
    volumes:
      - "./data/mongodb:/opt/app"
    command: [ "/bin/sh", "-c", "/opt/app/my_data.sh" ]
    depends_on:
      - "mongodb-server"

  airflow:
    container_name: "airflow"
    image: "apache/airflow:2.9.1"
    command: "standalone"
    environment:
      - "AIRFLOW_UID=50000"
      - "AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/airflow"
      - "AIRFLOW__CORE__FERNET_KEY="
      - "AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true"
      - "AIRFLOW__CORE__LOAD_EXAMPLES=true"
      - "AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
    volumes:
      - "./data/airflow/dags:/opt/airflow/dags"
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    user: "50000:0"
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    container_name: "airflow-init"
    image: "apache/airflow:2.9.1"
    entrypoint: "/bin/bash"
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo "For other operating systems you can get rid of the warning with manually created .env file:"
          echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
          echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
          echo
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
          echo "At least 2 CPUs recommended. You have $${cpus_available}"
          echo
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
          echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
          echo
          warning_resources="true"
        fi
        if [[ $${warning_resources} == "true" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
          echo "Please follow the instructions to increase amount of resources available:"
          echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      - "AIRFLOW_UID=50000"
      - "AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/airflow"
      - "_AIRFLOW_DB_MIGRATE=true"
      - "_AIRFLOW_WWW_USER_CREATE=true"
      - "_AIRFLOW_WWW_USER_USERNAME=airflow"
      - "_AIRFLOW_WWW_USER_PASSWORD=airflow"
      - "_PIP_ADDITIONAL_REQUIREMENTS="
    user: "0:0"
    depends_on:
      postgres:
        condition: service_healthy
